<html>

<head>
<title>Practical Machine Learning </title>
</head>

<body>


<p> Peer-graded Assignment: Prediction Assignment Writeup
Title: "Practical Machine Learning: Assessment Report"
Author: "Ossama Embarak"
Date: "25/11/2019"
</p>


# Load relevant datasets

 
Training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
Testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
 


#Load packages we may need 

 
library(ISLR)
library(caret)
library(kernlab)
library(randomForest)
library(rattle)

library(ggplot2)

library(ElemStatLearn)

library(rpart)
library(rpart.plot)

 
Explore the Training dataset

 
dim(Training)
str(Training)
dim(Testing)
str(Testing)

 
Explore the Testing dataset

 
dim(Testing)
str(Testing)
dim(Testing)
str(Testing)
 

Data cleaning,  check the missing values and correct it

<!--
 
TrainingNNA <- Training[ , colSums(is.na(Training)) == 0]
dim(TrainingNNA)
str(TrainingNNA)
-->
 

Remove any irrelevant variables

 
remove = c('user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window',
           'num_window','X')
TrainingRV <- TrainingNNA[, -which(names(TrainingNNA) %in% remove)]
dim(TrainingRV)

 

Check variables with too low variance

 
NZV=  nearZeroVar(TrainingRV[sapply(TrainingRV, is.numeric)], saveMetrics = TRUE)
trainingNNZV = TrainingRV[,NZV[, 'nzv']==0]
dim(trainingNNZV)
str(trainingNNZV)

 


Check high correlated variables
 
CorrMX <- cor(na.omit(trainingNNZV[sapply(trainingNNZV, is.numeric)]))
dim(CorrMX)

 

The plot correlated variable  
 
corrvar <- expand.grid(row = 1:52, col = 1:52)
corrvar$correlation <- as.vector(CorrMX)
levelplot(correlation ~ row+ col, corrvar)

 

Maintain a cleaned copy
 
trainingRDC<-trainingNNZV

 

Create both training and testing datasets

 
inTrain <- createDataPartition(y=trainingRDC$classe, p=0.7, list=FALSE)
TrainingCleanedData <- trainingRDC[inTrain,]; 
testingData <- trainingRDC[-inTrain,]
dim(TrainingCleanedData);
dim(testingData)

 


Create decision tree with rpart from the caret package

 
library(caret)
set.seed(1000)
Model1_Trained<-rpart(classe~., data= TrainingCleanedData, control = rpart.control(xval = 5))
treeTraining<-train(classe ~., method = 'rpart', data=TrainingCleanedData)
summary(treeTraining)
print(treeTraining$Model1_Trained)

 

Use rattle to plot decision tree plot

 
library(rattle)
fancyRpartPlot(treeTraining$Model1_Trained)

 

Cross-validation of decision tree

 
treepredict<-predict(Model1_Trained,testing)
predOutput<-with(testing,table(treepredict,classe))
sum(diag(predOutput))/sum(as.vector(predOutput))  
 


Although the model function properly, but we could get better results 
Pruning the tree for better model performance 
 
cvtraining=cv.tree(Model1_Trained,FUN=prune.misclass)
cvtraining
plot(cvtraining)
 
 


Apply a random forest model...
 
library(randomForest)
set.seed(1000)

 


Forming the random forest model
 
Model2_ForestRND<- train(classe~., data = TrainingCleanedData, method = "rf", prox = TRUE)
Model2_ForestRND

 

Check the created model 
 
getTree(Model2_ForestRND$finalModel,k=2)

 

Eveluate the model predictions 
 
Evaluate_Model2_Pred<-predict(modFit,testingData); testingData$predRight<-pred==testingData$classe
table(Evaluate_Model2_Pred,testingData$classe)

 

The evaluation shows that the new model (Random Forest Model) is much better then the previous model (Decision Tree Model)
Evaluate the model agints the test data set 

 
FinalPredictions <- predict(Model2_ForestRND, testingData, type = "class")
FinalPredictions

ToFile = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("Case No:",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

ToFile(FinalPredictions)
 


End of the Assignment 

--->  

</body>
</html>
